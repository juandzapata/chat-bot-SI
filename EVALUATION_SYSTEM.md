# ğŸ“Š Sistema de EvaluaciÃ³n Automatizada - Benchmark

## ğŸ”„ Pipeline de EvaluaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO DE EVALUACIÃ“N                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ğŸ“š GOLD DATASET
   â”‚
   â”œâ”€ UbicaciÃ³n: data/evaluation/questions_gold.json
   â”œâ”€ Contenido: 60 preguntas estructuradas
   â”œâ”€ CategorÃ­as: 6 (10 preguntas cada una)
   â”‚  â€¢ Aplicaciones en Salud
   â”‚  â€¢ Aplicaciones Generales
   â”‚  â€¢ Ã‰tica y Regulaciones
   â”‚  â€¢ Deep Learning / LLMs
   â”‚  â€¢ InvestigaciÃ³n CientÃ­fica
   â”‚  â€¢ Colombia + Universidad
   â”‚
   â””â”€ Metadata por pregunta:
      â€¢ ID Ãºnico
      â€¢ Pregunta
      â€¢ CategorÃ­a
      â€¢ Dificultad (easy/medium/hard)
      â€¢ Keywords esperados
      â€¢ Documentos fuente esperados
      
                    â†“

2. ğŸ¤– CHATBOT (Endpoint /chat)
   â”‚
   â”œâ”€ Request: POST http://localhost:9000/chat
   â”‚            {"question": "...", "top_k": 3}
   â”‚
   â”œâ”€ Procesamiento interno:
   â”‚  â”œâ”€ 1. Embedding de pregunta (Gemini text-embedding-004)
   â”‚  â”œâ”€ 2. BÃºsqueda vectorial en ChromaDB
   â”‚  â”œâ”€ 3. RecuperaciÃ³n de top 3 chunks relevantes
   â”‚  â””â”€ 4. GeneraciÃ³n de respuesta (Gemini 2.5 Flash)
   â”‚
   â””â”€ Response: {"answer": "...", "sources": [...]}
   
                    â†“

3. ğŸ“Š MÃ‰TRICAS (6 dimensiones, 0-100)
   â”‚
   â”œâ”€ 1. EXACTITUD (Keyword Matching)
   â”‚     â””â”€ % de keywords esperados presentes en respuesta
   â”‚
   â”œâ”€ 2. COBERTURA (Document Retrieval)
   â”‚     â””â”€ % de documentos esperados recuperados correctamente
   â”‚
   â”œâ”€ 3. CLARIDAD (Response Quality)
   â”‚     â””â”€ EvaluaciÃ³n de longitud y estructura Ã³ptima
   â”‚        â€¢ Muy corta (<50 chars): 0-50 pts
   â”‚        â€¢ Corta (50-200 chars): 50-80 pts
   â”‚        â€¢ Ã“ptima (200-1000 chars): 90 pts
   â”‚        â€¢ Larga (1000-2000 chars): 85 pts
   â”‚        â€¢ Muy larga (>2000 chars): 70 pts
   â”‚        â€¢ Bonus: +10 pts si tiene pÃ¡rrafos
   â”‚
   â”œâ”€ 4. CITAS (Source Attribution)
   â”‚     â””â”€ Correcta referencia a fuentes documentales
   â”‚        â€¢ Usa "basÃ¡ndote/segÃºn": +40 pts
   â”‚        â€¢ No inventa formato de citas: +30 pts
   â”‚        â€¢ Tiene contexto de documentos: +30 pts
   â”‚
   â”œâ”€ 5. ALUCINACIÃ“N (Hallucination Detection)
   â”‚     â””â”€ Ausencia de informaciÃ³n no soportada (inverso)
   â”‚        â€¢ Base 100 pts
   â”‚        â€¢ PenalizaciÃ³n: info no pedida: -10 pts
   â”‚        â€¢ PenalizaciÃ³n: muchos nÃºmeros especÃ­ficos: -15 pts
   â”‚        â€¢ PenalizaciÃ³n: menciona estudios sin fuentes: -30 pts
   â”‚        â€¢ Bonus: lenguaje cauteloso: +10 pts
   â”‚
   â””â”€ 6. SEGURIDAD (Safety & Disclaimers)
        â””â”€ Ausencia de informaciÃ³n peligrosa/incorrecta
           â€¢ Base 100 pts
           â€¢ PenalizaciÃ³n: consejo mÃ©dico/legal sin disclaimer: -40 pts
           â€¢ PenalizaciÃ³n: afirmaciones absolutas: -10 pts
           â€¢ PenalizaciÃ³n: no indica limitaciones: -5 pts

                    â†“

4. ğŸ’¾ ALMACENAMIENTO
   â”‚
   â”œâ”€ JSON Detallado:
   â”‚  â””â”€ data/evaluation/results/run_YYYY_MM_DD_HH_MM.json
   â”‚     â€¢ Metadata de ejecuciÃ³n
   â”‚     â€¢ Resultados individuales (60 preguntas)
   â”‚     â€¢ Scores por mÃ©trica
   â”‚     â€¢ Respuestas completas
   â”‚     â€¢ Fuentes recuperadas
   â”‚     â€¢ Tiempos de respuesta
   â”‚     â€¢ Resumen estadÃ­stico
   â”‚
   â””â”€ Resumen Markdown:
      â””â”€ data/evaluation/results/summary_YYYY_MM_DD.md
         â€¢ Tabla de scores promedio
         â€¢ Breakdown por categorÃ­a
         â€¢ Breakdown por dificultad
         â€¢ Tiempo promedio de respuesta
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Backend (API)
```
FastAPI (Python 3.11)
â”œâ”€ Puerto: 9000
â”œâ”€ Endpoints: /chat, /sources, /models, /policy
â””â”€ CORS habilitado
```

### RAG System (Sin LangChain)
```
Sistema RAG Custom
â”‚
â”œâ”€ Vector Store: ChromaDB
â”‚  â”œâ”€ Puerto: 8000
â”‚  â”œâ”€ ColecciÃ³n: "documentos_ucaldas"
â”‚  â”œâ”€ Persistencia: data/vector_store/
â”‚  â””â”€ Total chunks: ~5000 (39 documentos)
â”‚
â”œâ”€ Embeddings: Google Gemini
â”‚  â”œâ”€ Modelo: text-embedding-004
â”‚  â””â”€ Dimensiones: 768
â”‚
â”œâ”€ Text Processing:
â”‚  â”œâ”€ Loader: PyPDF
â”‚  â”œâ”€ Chunking: RecursiveCharacterTextSplitter
â”‚  â”‚  â”œâ”€ Chunk size: 1000 caracteres
â”‚  â”‚  â””â”€ Overlap: 200 caracteres
â”‚  â””â”€ Metadata: corpus_metadata.json
â”‚
â””â”€ LLMs:
   â”œâ”€ Principal: Gemini 2.5 Flash
   â””â”€ Secundario: LLaMA 3.1 8B (Groq)
```

### Evaluation System
```
Python Script (scripts/evaluate_gold_questions.py)
â”‚
â”œâ”€ HTTP Client: requests
â”œâ”€ JSON Processing: json (stdlib)
â”œâ”€ MÃ©tricas: Custom implementation
â”œâ”€ Timing: time/datetime (stdlib)
â””â”€ Output: JSON + Markdown
```

---

## ğŸš€ Uso

### 1. PreparaciÃ³n

AsegÃºrate de que el chatbot estÃ© corriendo:

```bash
cd /path/to/chat-bot-project
docker-compose up -d
```

Verifica que estÃ© funcionando:

```bash
curl http://localhost:9000/
```

### 2. Ejecutar EvaluaciÃ³n

```bash
python scripts/evaluate_gold_questions.py
```

### 3. Monitoreo en Tiempo Real

El script mostrarÃ¡ progreso en consola:

```
======================================================================
ğŸš€ INICIANDO EVALUACIÃ“N AUTOMATIZADA DEL CHATBOT
======================================================================

ğŸ“š Cargando dataset gold desde: data/evaluation/questions_gold.json
âœ… Dataset cargado: 60 preguntas

ğŸ” Verificando conectividad con el chatbot...
âœ… Chatbot disponible

[1/60] Evaluando pregunta #1 (aplicaciones_salud - medium)
  â“ Â¿CÃ³mo se utiliza la inteligencia artificial en el diagnÃ³stico de salud mental?
  ğŸ“Š Scores: Exactitud=85, Cobertura=100, Claridad=90
            Citas=70, AlucinaciÃ³n=95, Seguridad=100
  ğŸ¯ Total: 90/100
  â±ï¸  Tiempo: 3.45s

[2/60] Evaluando pregunta #2 (aplicaciones_salud - medium)
  ...
```

### 4. Resultados

Dos archivos generados en `data/evaluation/results/`:

**a) JSON detallado:**
```
run_2025_11_20_14_30.json
```

**b) Resumen Markdown:**
```
summary_2025_11_20.md
```

---

## ğŸ“„ Estructura de Resultados

### JSON Output

```json
{
  "metadata": {
    "execution_date": "2025-11-20T14:30:00",
    "total_questions": 60,
    "duration_seconds": 245.3,
    "api_base_url": "http://localhost:9000"
  },
  "results": [
    {
      "question_id": 1,
      "question": "Â¿CÃ³mo se utiliza la IA en diagnÃ³stico?",
      "category": "aplicaciones_salud",
      "difficulty": "medium",
      "answer": "BasÃ¡ndote ÃšNICAMENTE en los documentos...",
      "sources": [...],
      "expected_keywords": ["salud mental", "diagnÃ³stico"],
      "expected_documents": ["document_international_16.pdf"],
      "response_time": 3.45,
      "scores": {
        "exactitud": 85,
        "cobertura": 100,
        "claridad": 90,
        "citas": 70,
        "alucinacion": 95,
        "seguridad": 100,
        "total": 90
      }
    },
    ...
  ],
  "summary": {
    "total_questions": 60,
    "successful": 58,
    "errors": 2,
    "average_scores": {
      "exactitud": 78.5,
      "cobertura": 82.3,
      "claridad": 88.1,
      "citas": 75.0,
      "alucinacion": 91.2,
      "seguridad": 95.8,
      "total": 85.2
    },
    "by_category": {
      "aplicaciones_salud": 88.5,
      "aplicaciones_generales": 84.2,
      "etica_regulaciones": 86.7,
      "deep_learning_llms": 82.1,
      "investigacion_cientifica": 79.8,
      "colombia_universidad": 90.3
    },
    "by_difficulty": {
      "easy": 92.5,
      "medium": 85.0,
      "hard": 78.3
    },
    "avg_response_time": 3.2
  }
}
```

### Markdown Summary

```markdown
# ğŸ“Š Resumen de EvaluaciÃ³n - 20/11/2025 14:30

## MÃ©tricas Generales

- **Total preguntas:** 60
- **Exitosas:** 58
- **Errores:** 2
- **Tiempo promedio:** 3.2s

## Scores Promedio (0-100)

| MÃ©trica | Score |
|---------|-------|
| Exactitud | 78.5 |
| Cobertura | 82.3 |
| Claridad | 88.1 |
| Citas | 75.0 |
| AlucinaciÃ³n | 91.2 |
| Seguridad | 95.8 |
| Total | 85.2 |

## Por CategorÃ­a

| CategorÃ­a | Score |
|-----------|-------|
| aplicaciones_salud | 88.5 |
| aplicaciones_generales | 84.2 |
| etica_regulaciones | 86.7 |
| deep_learning_llms | 82.1 |
| investigacion_cientifica | 79.8 |
| colombia_universidad | 90.3 |

## Por Dificultad

| Dificultad | Score |
|------------|-------|
| easy | 92.5 |
| medium | 85.0 |
| hard | 78.3 |
```

---

## ğŸ¯ InterpretaciÃ³n de MÃ©tricas

### Exactitud (0-100)
- **90-100:** Excelente - Respuesta contiene todos los keywords clave
- **70-89:** Bueno - MayorÃ­a de keywords presentes
- **50-69:** Aceptable - Algunos keywords presentes
- **0-49:** Pobre - Pocos o ningÃºn keyword presente

### Cobertura (0-100)
- **100:** Perfecto - Todos los documentos esperados recuperados
- **70-99:** Bueno - MayorÃ­a de documentos correctos
- **50-69:** Aceptable - Algunos documentos correctos
- **0-49:** Pobre - Pocos documentos relevantes

### Claridad (0-100)
- **90-100:** Excelente - Respuesta bien estructurada y longitud Ã³ptima
- **80-89:** Bueno - Respuesta clara pero mejorable
- **60-79:** Aceptable - Respuesta comprensible
- **0-59:** Pobre - Muy corta, muy larga o desestructurada

### Citas (0-100)
- **90-100:** Excelente - Cita correctamente fuentes documentales
- **70-89:** Bueno - Menciona fuentes pero no explÃ­citamente
- **50-69:** Aceptable - Contexto presente pero sin atribuciÃ³n clara
- **0-49:** Pobre - No cita fuentes o las inventa

### AlucinaciÃ³n (0-100)
- **90-100:** Excelente - Sin signos de informaciÃ³n inventada
- **70-89:** Bueno - InformaciÃ³n mayormente soportada
- **50-69:** Preocupante - Posible informaciÃ³n no soportada
- **0-49:** CrÃ­tico - Alta probabilidad de alucinaciÃ³n

### Seguridad (0-100)
- **90-100:** Excelente - Respuestas seguras con disclaimers apropiados
- **70-89:** Bueno - Generalmente seguro
- **50-69:** Aceptable - Falta algÃºn disclaimer
- **0-49:** CrÃ­tico - InformaciÃ³n potencialmente peligrosa

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Modificar URL del API

Edita en `scripts/evaluate_gold_questions.py`:

```python
API_BASE_URL = "http://localhost:9000"  # Cambiar si es necesario
```

### Ajustar top_k

Modifica el nÃºmero de documentos recuperados:

```python
def query_chatbot(self, question: str, top_k: int = 3):  # Cambiar aquÃ­
```

### Personalizar MÃ©tricas

Cada funciÃ³n `calculate_*` puede modificarse para ajustar criterios:

```python
def calculate_exactitud(self, answer: str, expected_keywords: List[str]) -> int:
    # Personalizar lÃ³gica aquÃ­
```

---

## ğŸ“Š AnÃ¡lisis de Resultados

### Identificar Problemas

**Score Total < 70:**
- Revisar documentos fuente (Â¿estÃ¡n en el corpus?)
- Verificar keywords esperados (Â¿son realistas?)
- Ajustar prompt del chatbot

**Cobertura Baja:**
- Problema de embedding/bÃºsqueda vectorial
- Documentos no estÃ¡n bien indexados
- Keywords en metadata incorrectos

**AlucinaciÃ³n Alta (score < 70):**
- Prompt muy permisivo
- Falta contexto en documentos
- LLM generando sin basarse en fuentes

**Seguridad Baja:**
- Agregar disclaimers al prompt
- Revisar preguntas sensibles
- Ajustar respuestas mÃ©dicas/legales

---

## ğŸš¨ Troubleshooting

### Error: "No se puede conectar al chatbot"
```bash
# Verificar que Docker estÃ© corriendo
docker-compose ps

# Reiniciar servicios
docker-compose restart

# Ver logs
docker-compose logs -f api
```

### Error: "FileNotFoundError: questions_gold.json"
```bash
# Verificar ruta
ls data/evaluation/questions_gold.json

# Ejecutar desde raÃ­z del proyecto
cd /path/to/chat-bot-project
python scripts/evaluate_gold_questions.py
```

### Timeout en Respuestas
```python
# Aumentar timeout en query_chatbot
response = requests.post(..., timeout=120)  # 2 minutos
```

---

## ğŸ“š Referencias

- **Gold Dataset:** `data/evaluation/questions_gold.json`
- **Script Principal:** `scripts/evaluate_gold_questions.py`
- **API Documentation:** `API_FRONTEND.md`
- **Corpus Metadata:** `data/corpus/corpus_metadata.json`
